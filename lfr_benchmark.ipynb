{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from networkx.algorithms.community import modularity\n",
    "from networkx.generators.community import LFR_benchmark_graph\n",
    "import community.community_louvain\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods to draw communities start\n",
    "def community_layout(g, partition):\n",
    "    \"\"\" Compute the layout for a modular graph.\n",
    "    \"\"\"\n",
    "    pos_communities = _position_communities(g, partition, scale=3.)\n",
    "\n",
    "    pos_nodes = _position_nodes(g, partition, scale=1.)\n",
    "\n",
    "    # combine positions\n",
    "    pos = dict()\n",
    "    for node in g.nodes():\n",
    "        pos[node] = pos_communities[node] + pos_nodes[node]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _position_communities(g, partition, **kwargs):\n",
    "\n",
    "    # create a weighted graph, in which each node corresponds to a community,\n",
    "    # and each edge weight to the number of edges between communities\n",
    "    between_community_edges = _find_between_community_edges(g, partition)\n",
    "\n",
    "    communities = set(partition.values())\n",
    "    hypergraph = nx.DiGraph()\n",
    "    hypergraph.add_nodes_from(communities)\n",
    "    for (ci, cj), edges in between_community_edges.items():\n",
    "        hypergraph.add_edge(ci, cj, weight=len(edges))\n",
    "\n",
    "    # find layout for communities\n",
    "    pos_communities = nx.spring_layout(hypergraph, **kwargs)\n",
    "\n",
    "    # set node positions to position of community\n",
    "    pos = dict()\n",
    "    for node, community in partition.items():\n",
    "        pos[node] = pos_communities[community]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _find_between_community_edges(g, partition):\n",
    "\n",
    "    edges = dict()\n",
    "\n",
    "    for (ni, nj) in g.edges():\n",
    "        ci = partition[ni]\n",
    "        cj = partition[nj]\n",
    "\n",
    "        if ci != cj:\n",
    "            try:\n",
    "                edges[(ci, cj)] += [(ni, nj)]\n",
    "            except KeyError:\n",
    "                edges[(ci, cj)] = [(ni, nj)]\n",
    "\n",
    "    return edges\n",
    "\n",
    "def _position_nodes(g, partition, **kwargs):\n",
    "    \"\"\"Positions nodes within communities.\n",
    "    \"\"\"\n",
    "    communities = dict()\n",
    "    for node, community in partition.items():\n",
    "        try:\n",
    "            communities[community] += [node]\n",
    "        except KeyError:\n",
    "            communities[community] = [node]\n",
    "\n",
    "    pos = dict()\n",
    "    for ci, nodes in communities.items():\n",
    "        subgraph = g.subgraph(nodes)\n",
    "        pos_subgraph = nx.spring_layout(subgraph, **kwargs)\n",
    "        pos.update(pos_subgraph)\n",
    "\n",
    "    return pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Methods to draw communities end\n",
    "\n",
    "# Building graph of 30k nodes\n",
    "def buildGraph():\n",
    "    G1 = nx.Graph()\n",
    "    G1 = nx.read_adjlist(\"sampled_graph_30k.adjlist\")\n",
    "    return G1\n",
    "\n",
    "# Returns the original graph after building it from txt file.\n",
    "def getOriginalGraph():\n",
    "\tfile1 = open('./data/com-amazon.ungraph.txt', 'r')\n",
    "\tLines = file1.readlines()\n",
    "\tG = nx.Graph()\n",
    "\tfor line in Lines:\n",
    "\t\ta, b = line.strip().split(\"\\t\")\n",
    "\t\tG.add_edge(a, b)\n",
    "\treturn G\n",
    "\n",
    "# Build mapping between nodes and product ids\n",
    "def createGraphNodesMapping(): \n",
    "\tG = getOriginalGraph()\n",
    "\tmapping = {int(v):k for k, v in enumerate(list(G.nodes))}\n",
    "\treturn mapping\n",
    "\n",
    "\n",
    "# Builds an adjcency list from original grpah\n",
    "def buildAdjList():\n",
    "\n",
    "\tmapping = createGraphNodesMapping()\n",
    "\t\n",
    "\tGnew = nx.Graph()\n",
    "\tfile = open('./data/com-amazon.ungraph.txt', 'r')\n",
    "\tLines = file.readlines()\n",
    "\t\n",
    "\tfor line in Lines:\n",
    "\t\ta, b = line.strip().split(\"\\t\")\n",
    "\t\tGnew.add_edge(mapping.get(int(a)), mapping.get(int(b)))\n",
    "\tG1 = communitySampling(Gnew, 30000)\n",
    "\tnx.write_adjlist(G1, \"sampled_graph_30k.adjlist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Degree distribution of the network\n",
    "def plotDegDist():\n",
    "    G = buildGraph()\n",
    "    n = G.number_of_nodes()\n",
    "    degreeFreq = {}\n",
    "    degrees = [G.degree(node) for node in G.nodes()]\n",
    "    for degree in degrees:\n",
    "        degreeFreq[degree] = degreeFreq.get(degree, 0) + 1\n",
    "    (X, Y) = zip(*[(degree, degreeFreq[degree] / n) for degree in degreeFreq])\n",
    "    plt.scatter(X, Y, c='b', alpha=0.5)\n",
    "    plt.title('Degree Distribution')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Degree')\n",
    "    plt.ylabel('Density')\n",
    "    plt.savefig('degreeDistribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecting best communities from ground-truth communities\n",
    "def buildCommunities():\n",
    "    idToNodeMap = createGraphNodesMapping()\n",
    "\n",
    "    file3 = open('./data/com-amazon.all.dedup.cmty.txt', 'r')\n",
    "    Lines = file3.readlines()\n",
    "\n",
    "    communities=[]\n",
    "    for i in range(75150):\n",
    "        communities.append([])\n",
    "    i=0\n",
    "    for line in Lines:\n",
    "        a = line.strip().split(\"\\t\")\n",
    "        for n in a:\n",
    "            communities[i].append(idToNodeMap[int(n)])\n",
    "        i+=1\n",
    "\n",
    "    for i, comm in enumerate(communities):\n",
    "        communities[i] = set(comm)\n",
    "\n",
    "    nodes = list(idToNodeMap.values())\n",
    "    nodeCommMapping = {}\n",
    "    for node in nodes:\n",
    "        prevLen = -1\n",
    "        for i, comm in enumerate(communities):\n",
    "            if node in comm:\n",
    "                if len(comm) > prevLen:\n",
    "                    nodeCommMapping[node] = i\n",
    "                    prevLen = len(comm)\n",
    "\n",
    "    f = open(\"nodeCommunities.txt\", \"a\")    \n",
    "    for key in nodeCommMapping:\n",
    "        f.write(str(key) + ' ' + str(nodeCommMapping[key]) + '\\n')\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# <Section - Detecting communities using Greedy modularity, Girvan newman and Louvain algorithm>\n",
    "def greedyModularityCommunities(G):\n",
    "    partition = greedy_modularity_communities(G)\n",
    "    part = []\n",
    "    i=0\n",
    "    a={}\n",
    "    for s in partition:\n",
    "        for x in s:\n",
    "            part.append(x)\n",
    "            a[x]=i\n",
    "        i += 1\n",
    "  \n",
    "    pos = community_layout(G, a)\n",
    "    figure(figsize = (10, 8), dpi = 100)\n",
    "    nx.draw(G, pos, node_color=list(a.values()))\n",
    "    plt.show()\n",
    "\n",
    "def girvanNewmanCommunityDetection(G):\n",
    "\tgirvanNewmanCommunities = nx.algorithms.community.centrality.girvan_newman(G)\n",
    "\tmax_modularity = float('-inf')\n",
    "\tbestPartition = tuple()\n",
    "\n",
    "\tfor communities in itertools.islice(girvanNewmanCommunities, 2):\n",
    "\t\ta = tuple(c for c in communities)\n",
    "\t\tQ = modularity(G, a)\n",
    "\t\tif Q > max_modularity:\n",
    "\t\t\tmax_modularity = Q\n",
    "\t\t\tbestPartition = a\n",
    "\ti=0\n",
    "\ta={}\n",
    "\tfor s in bestPartition:\n",
    "\t\tfor x in s:\n",
    "\t\t\ta[x]=i\n",
    "\t\ti += 1\n",
    "\tpos = community_layout(G, a)\n",
    "\tfigure(figsize = (10, 8), dpi = 100)\n",
    "\tnx.draw(G, pos, node_color=list(a.values()))\n",
    "\tplt.show()\n",
    "\n",
    "def louvainCommunities(G):\n",
    "    partition = community.community_louvain.best_partition(G)\n",
    "\n",
    "    pos = community_layout(G, partition)\n",
    "    figure(figsize = (10, 8), dpi = 100)\n",
    "    nx.draw(G, pos, node_color=list(partition.values()))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# <Section - Accuracy for Louvain and Greedy Modularity>\n",
    "def getGroundTruthCommList():\n",
    "    G1 = buildGraph()\n",
    "    nodes = set(G1.nodes())\n",
    "    f = open('community_nodes_30k.txt', 'r')\n",
    "    lines = f.readlines()\n",
    "    communityList = []\n",
    "    for line in lines:\n",
    "        split = line.strip().split('->')\n",
    "        nodesInComm = split[1].strip().split(' ')\n",
    "        label = split[0]\n",
    "        for node in nodesInComm:\n",
    "            if node in nodes:\n",
    "                communityList.append(label)\n",
    "    return communityList\n",
    "\n",
    "def getGroundTruthNodes():\n",
    "    G1 = buildGraph()\n",
    "    nodes = set(G1.nodes())\n",
    "    f = open('node_comm_mapping_all.txt', 'r')\n",
    "    lines = f.readlines()\n",
    "    nodeList = []\n",
    "    for line in lines:\n",
    "        split = line.strip().split(' ')\n",
    "        if split[0] in nodes:\n",
    "            nodeList.append(split[0])\n",
    "    return nodeList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def louvainCommDetNMI():\n",
    "\tG1 = buildGraph()\n",
    "\tpartition = community.community_louvain.best_partition(G1)\n",
    "\n",
    "\tgroundTruthCommList = getGroundTruthCommList()\n",
    "\tgroundTruthNodes = set(getGroundTruthNodes())\n",
    "\n",
    "\tcommunityList=[]\n",
    "\tfor nodes in G1.nodes():\n",
    "\t\tif nodes in groundTruthNodes:\n",
    "\t\t\tcommunityList.append(partition[nodes])\n",
    "            \n",
    "\tNMI = normalized_mutual_info_score(groundTruthCommList, communityList)\n",
    "\n",
    "def greedyCommDetNMI():\n",
    "    G1 = buildGraph()\n",
    "    greedyModularity = greedy_modularity_communities(G1)\n",
    "    \n",
    "    groundTruthCommList = getGroundTruthCommList()\n",
    "    groundTruthNodes = set(getGroundTruthNodes())\n",
    "\n",
    "    communityList=[]\n",
    "    for node in G1.nodes():\n",
    "        i=0\n",
    "        for x in greedyModularity:\n",
    "            if node in x and node in groundTruthNodes:                \n",
    "                communityList.append(i)\n",
    "                break\n",
    "            i+=1\n",
    "    NMI = normalized_mutual_info_score(groundTruthCommList, communityList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# <Section - LFR ------------------------------------------------------------>\n",
    "def getTau1(G):\n",
    "  degrees = {}\n",
    "  degreeList = [G.degree(v) for v in G.nodes()]\n",
    "  for deg in degreeList:\n",
    "    degrees[deg] = degrees.get(deg, 0) + 1\n",
    "\n",
    "  (X, Y) = zip(*[(key,degrees[key]/len(G)) for key in degrees]) \n",
    "  (logX, logY) = ([np.log10(x) for x in X], [np.log10(y) for y in Y])\n",
    "\n",
    "  resultLogLog = stats.linregress(logX, logY)\n",
    "  return resultLogLog.slope*-1\n",
    "\n",
    "def getTau2(label_to_nodeList):\n",
    "  X=[]\n",
    "  Y=[]\n",
    "  communityLengths = []\n",
    "  for key in label_to_nodeList:\n",
    "    length = len(label_to_nodeList[key])\n",
    "    communityLengths.append(length)\n",
    "    \n",
    "  communityDist = {}\n",
    "  for n in communityLengths:\n",
    "    communityDist[n] = communityDist.get(n, 0) + 1\n",
    "\n",
    "  (X, Y) = zip(*[(n, communityDist[n] / len(label_to_nodeList)) for n in communityDist])\n",
    "\n",
    "  (logX, logY) = ([np.log10(x) for x in X], [np.log10(y) for y in Y])\n",
    "\n",
    "  resultLogLog = stats.linregress(logX, logY)\n",
    "  return resultLogLog.slope*-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plotLFR():\n",
    "\n",
    "    G1 = buildGraph()\n",
    "    groundTruthNodes = set(getGroundTruthNodes())\n",
    "\n",
    "    # Greedy Modularity\n",
    "    greedyModularity = greedy_modularity_communities(G1)\n",
    "    communityList=[]\n",
    "    for node in G1.nodes():\n",
    "        i=0\n",
    "        for x in greedyModularity:\n",
    "            if node in x and node in groundTruthNodes:                \n",
    "                communityList.append(i)\n",
    "                break\n",
    "            i+=1\n",
    "    label_to_nodeList={}\n",
    "    a = set(communityList.values())\n",
    "    for values in a:\n",
    "        label_to_nodeList[values] = []\n",
    "    for x in communityList:\n",
    "        label_to_nodeList[communityList[x]].append(int(x))\n",
    "    tau1 = getTau1(G1)\n",
    "    tau2 = getTau2(label_to_nodeList)\n",
    "    X = []\n",
    "    Y = []\n",
    "    for mu in np.arange(0.1, 1, 0.05):\n",
    "        X.append(mu)\n",
    "        G = LFR_benchmark_graph(29268, tau1, tau2, mu, average_degree=5, max_degree=50, min_community=20, max_community=100)\n",
    "        communities = [(G.nodes[v][\"community\"]) for v in G]\n",
    "        NMI = normalized_mutual_info_score(communities, communityList)\n",
    "        Y.append(NMI)\n",
    "\n",
    "    plt.plot(X, Y, '-o', label='Greedy Modularity', alpha=0.5)\n",
    "\n",
    "    # Louvain\n",
    "    partition = community.community_louvain.best_partition(G1)\n",
    "\n",
    "    communityList=[]\n",
    "    for nodes in G1.nodes():\n",
    "        if nodes in groundTruthNodes:\n",
    "            communityList.append(partition[nodes])\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    for mu in np.arange(0.1, 1, 0.05):\n",
    "        X.append(mu)\n",
    "        G = LFR_benchmark_graph(29268, tau1, tau2, mu, average_degree=5, max_degree=50, min_community=20, max_community=100)\n",
    "        communities = [(G.nodes[v][\"community\"]) for v in G]\n",
    "        NMI = normalized_mutual_info_score(communities, communityList)\n",
    "        Y.append(NMI)\n",
    "\n",
    "    plt.plot(X, Y, '-o', label='Louvain', alpha=0.5)\n",
    "    plt.title('NMI vs Mixing Parameter')\n",
    "    plt.xlabel('Mixing Parameter')\n",
    "    plt.ylabel('Normalised Mutual Information')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.savefig('NMI_vs_mu_greedy.png')\n",
    "\n",
    "def snowballsampling( G, seed, maxN):\n",
    "    subgraph = set(seed)\n",
    "    for x in seed:\n",
    "        for e in nx.bfs_tree(G, source=x).nodes():\n",
    "            if len(subgraph) < maxN:\n",
    "                subgraph.add(e)\n",
    "            else:\n",
    "                return G.subgraph(subgraph)\n",
    "    return G.subgraph(subgraph)\n",
    "\n",
    "def randomWalkSample(G, seeds, steps):\n",
    "    G_ = nx.Graph()\n",
    "    for seed in seeds:\n",
    "        source = seed\n",
    "        for _ in range(steps):\n",
    "            neigh = [node for node in G.neighbors(source)]\n",
    "            if len(neigh) == 0:\n",
    "                break\n",
    "            target = np.random.choice(neigh, size=1)[0]\n",
    "            G_.add_edge(source, target)\n",
    "            source = target\n",
    "    return G_\n",
    "\t \n",
    "def communitySampling(G: nx.Graph, sampleSize):\n",
    "\trandomNodes = set(random.sample(G.nodes(), 1))\n",
    "\twhile len(randomNodes) < sampleSize:\n",
    "\t\tneighbors = [ neighbor\n",
    "\t\t\t\tfor node in randomNodes\n",
    "\t\t\t\tfor neighbor in G.neighbors(node) ]\n",
    "\t\tneighbors = list(set(neighbors).difference(randomNodes))\n",
    "\t\trandom.shuffle(neighbors)\n",
    "\t\texpansion = 0\n",
    "\t\tfor node in neighbors:\n",
    "\t\t\tnewNode = random.choice(list(G.neighbors(node)))\n",
    "\t\t\tnewExpansion = len(set(G.neighbors(node)).difference(randomNodes))\n",
    "\t\t\tif newExpansion >= expansion:\n",
    "\t\t\t\texpansion = newExpansion\n",
    "\t\t\t\tnewNode = node\n",
    "\t\trandomNodes.add(newNode)\n",
    "\treturn G.subgraph(randomNodes)\n",
    "\n",
    "def comLens(communities):\n",
    "\tcomLenList = []\n",
    "\tfor i in communities:\n",
    "\t\tcomLenList.append(len(i))\n",
    "\treturn sorted(comLenList)\n",
    "\n",
    "def getSampledGroundTruth(nodes):\n",
    "\n",
    "\tnewComs = {}\n",
    "\tfile = open('email-Eu-core-department-labels.txt', 'r')\n",
    "\t\n",
    "\tfor line in file:\n",
    "\t\tcom =  line.strip().split(\" \")\n",
    "\t\tif int(com[0]) in nodes:\n",
    "\t\t\tnewComs[int(com[0])]=int(com[1])\n",
    "\n",
    "\tallComs={}\n",
    "\tfor key, val in newComs.items():\n",
    "\t\tallComs[val] = allComs.get(val, []) + [key]\n",
    "\n",
    "\treturn allComs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plotSamplingMethods():\n",
    "\tfile1 = open('email-Eu-core.txt', 'r')\n",
    "\tLines = file1.readlines()\n",
    "\tG = nx.Graph()\n",
    "\tfor line in Lines:\n",
    "\t\ta, b = line.strip().split(\" \")\n",
    "\t\tG.add_edge(int(a), int(b))\n",
    "\t\n",
    "\tlargest_cc = max(nx.connected_components(G), key=len)\n",
    "\tGcc = G.subgraph(largest_cc)\n",
    "\n",
    "\tmapping = {v:k for k, v in enumerate(list(Gcc.nodes))}\n",
    "\n",
    "\tGnew = nx.Graph()\n",
    "\tfile1 = open('email-Eu-core.txt', 'r')\n",
    "\tLines = file1.readlines()\n",
    "\tfor line in Gcc.edges:\n",
    "\t\tGnew.add_edge(mapping.get(line[0]), mapping.get(line[1]))\n",
    "\n",
    "\trandomNode = random.choice(Gnew.nodes)\n",
    "\n",
    "\tG1 = randomWalkSample(Gnew, randomNode, 500)\n",
    "\tgreedyModularity = greedy_modularity_communities(G1)\n",
    "\tplt.plot(comLens(greedyModularity), label = \"Random Walk\")\n",
    "\tplt.plot(comLens(getSampledGroundTruth(list(G1.nodes)).values()), label = \"Ground Truth\")\n",
    "\tplt.legend(loc='upper right')\n",
    "\tplt.xlabel('Number of communities')\n",
    "\tplt.ylabel('Community Size (sorted)')\n",
    "\tplt.savefig(\"Random\", bbox_inches='tight')\n",
    "\tplt.clf()\n",
    "\n",
    "\tG1 = snowballsampling(Gnew, randomNode, 500)\n",
    "\tgreedyModularity = greedy_modularity_communities(G1)\n",
    "\tplt.plot(comLens(greedyModularity), label = \"Snowball\")\n",
    "\tplt.plot(comLens(getSampledGroundTruth(list(G1.nodes)).values()), label = \"Ground Truth\")\n",
    "\tplt.legend(loc='upper right')\n",
    "\tplt.xlabel('Number of communities')\n",
    "\tplt.ylabel('Community Size (sorted)')\n",
    "\tplt.savefig(\"Snowball\", bbox_inches='tight')\n",
    "\tplt.clf()\n",
    "\n",
    "\t\n",
    "\tG1 = communitySampling(Gnew, 500)\n",
    "\t\n",
    "\tgreedyModularity = greedy_modularity_communities(G1)\n",
    "\tplt.plot(comLens(greedyModularity), label = \"Expander\")\n",
    "\tplt.plot(comLens(getSampledGroundTruth(list(G1.nodes)).values()), label = \"Ground Truth\")\n",
    "\tplt.legend(loc='upper right')\n",
    "\tplt.xlabel('Number of communities')\n",
    "\tplt.ylabel('Community Size (sorted)')\n",
    "\tplt.savefig(\"Expander\", bbox_inches='tight')\n",
    "\tplt.clf()\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsury\\AppData\\Local\\Temp\\ipykernel_13384\\138480694.py:83: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  randomNodes = set(random.sample(G.nodes(), 1))\n"
     ]
    }
   ],
   "source": [
    "buildAdjList()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "989f1c85a0753a3f5387357a9d8cdada932b18385ad81a9223bb8329c9a4fd3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
